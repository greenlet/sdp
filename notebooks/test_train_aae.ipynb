{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime as dt\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "import shutil\n",
    "import traceback\n",
    "from typing import Union, Any, Optional\n",
    "import yaml\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sdp.ds.bop_data import read_models_info, read_scene_camera, read_scene_gt, \\\n",
    "    read_scene_gt_info\n",
    "from sdp.ds.bop_dataset import BopDataset\n",
    "from sdp.ds.bop_dataset import AUGNAME_DEFAULT\n",
    "from sdp.models.segmenter.factory import create_segmenter\n",
    "from segm.optim.factory import create_optimizer, create_scheduler\n",
    "\n",
    "from b_01_train_aae import Config, TrainCfg, stack_imgs_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOP path: /Users/misha/data/bop\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME/data'))\n",
    "BOP_PATH = DATA_PATH / 'bop'\n",
    "ITODD_SUBDIR = 'itodd'\n",
    "ITODD_BOP_PATH = BOP_PATH / ITODD_SUBDIR\n",
    "print(f'BOP path: {BOP_PATH}')\n",
    "TRAIN_ROOT_PATH = DATA_PATH / 'train_aae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainCfg(bop_root_path=PosixPath('/Users/misha/data/bop'), train_root_path=PosixPath('/Users/misha/data/train_aae'), train_subdir='ds_itodd_obj_1_imsz_256_20231011_225846', dataset_name='itodd', obj_id=1, dt=datetime.datetime(2023, 10, 11, 22, 58, 46, 619260), img_size=256, last_epoch=0, epochs=100, batch_size=10, train_path=PosixPath('/Users/misha/data/train_aae/ds_itodd_obj_1_imsz_256_20231011_225846'), last_checkpoint_fpath=PosixPath('/Users/misha/data/train_aae/ds_itodd_obj_1_imsz_256_20231011_225846/last.pth'), best_checkpoint_fpath=PosixPath('/Users/misha/data/train_aae/ds_itodd_obj_1_imsz_256_20231011_225846/best.pth'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = Config(bop_root_path=BOP_PATH, train_root_path=TRAIN_ROOT_PATH, dataset_name=ITODD_SUBDIR,\n",
    "             obj_id=1, img_size=256, train_subdir='last')\n",
    "tcfg = TrainCfg.from_cfg(cfg)\n",
    "tcfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset from /Users/misha/data/bop/itodd/.sdp/v0.0.1\n",
      "min_mask_ratio: 20671 --> 18066\n",
      "min_bbox_dim_ratio: 18066 --> 16071\n",
      "default_cfg: {'url': 'https://storage.googleapis.com/vit_models/augreg/Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz', 'file': None, 'state_dict': None, 'hf_hub_id': None, 'hf_hub_filename': None, 'source': None, 'architecture': None, 'tag': None, 'custom_load': True, 'input_size': (3, 384, 384), 'test_input_size': None, 'min_input_size': None, 'fixed_input_size': True, 'interpolation': 'bicubic', 'crop_pct': 1.0, 'test_crop_pct': None, 'crop_mode': 'center', 'mean': (0.5, 0.5, 0.5), 'std': (0.5, 0.5, 0.5), 'num_classes': 1000, 'label_offset': None, 'label_names': None, 'label_descriptions': None, 'pool_size': None, 'test_pool_size': None, 'first_conv': 'patch_embed.proj', 'classifier': 'head', 'license': None, 'description': None, 'origin_url': None, 'paper_name': None, 'paper_ids': None, 'notes': None}\n",
      "load_custom_pretrained\n",
      "None https://storage.googleapis.com/vit_models/augreg/Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz None None None\n",
      "Segmenter(\n",
      "  (encoder): VisionTransformer(\n",
      "    (patch_embed): PatchEmbedding(\n",
      "      (proj): Conv2d(9, 192, kernel_size=(16, 16), stride=(16, 16))\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x Block(\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (mlp): FeedForward(\n",
      "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    (head): Linear(in_features=192, out_features=1000, bias=True)\n",
      "    (pre_logits): Identity()\n",
      "  )\n",
      "  (decoder): MaskTransformer(\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (mlp): FeedForward(\n",
      "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (mlp): FeedForward(\n",
      "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.100)\n",
      "      )\n",
      "    )\n",
      "    (proj_dec): Linear(in_features=192, out_features=192, bias=True)\n",
      "    (decoder_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    (mask_norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(cfg.device)\n",
    "skip_cache = False\n",
    "ds = BopDataset.from_dir(tcfg.bop_root_path, tcfg.dataset_name, 'train_pbr', shuffle=True, skip_cache=skip_cache)\n",
    "ds.shuffle()\n",
    "objs_view = ds.get_objs_view(tcfg.obj_id, tcfg.batch_size, tcfg.img_size, return_tensors=True,\n",
    "                                keep_source_images=False, keep_cropped_images=False)\n",
    "ov_train, ov_val = objs_view.split((-1, 0.1))\n",
    "ov_train.set_aug_name(AUGNAME_DEFAULT)\n",
    "it_buffer_sz = 10\n",
    "\n",
    "inp_ch, n_cls = 9, 6\n",
    "backbone = 'vit_tiny_patch16_384'\n",
    "model_cfg = {\n",
    "    'n_cls': n_cls,\n",
    "    'backbone': backbone,\n",
    "    'image_size': (tcfg.img_size, tcfg.img_size),\n",
    "    'channels': inp_ch,\n",
    "    'patch_size': 16,\n",
    "    'd_model': 192,\n",
    "    'n_heads': 3,\n",
    "    'n_layers': 12,\n",
    "    'normalization': 'vit',\n",
    "    'distilled': False,\n",
    "    'decoder': {\n",
    "        'name': 'mask_transformer',\n",
    "        'drop_path_rate': 0.1,\n",
    "        'dropout': 0.1,\n",
    "        'n_layers': 2\n",
    "    }\n",
    "}\n",
    "opt_cfg = {\n",
    "    'opt': 'sgd',\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 0.0,\n",
    "    'momentum': 0.9,\n",
    "    'clip_grad': None,\n",
    "    'sched': 'polynomial',\n",
    "    'epochs': tcfg.epochs,\n",
    "    'min_lr': 1e-5,\n",
    "    'poly_power': 0.9,\n",
    "    'poly_step_size': 1,\n",
    "    'iter_max': tcfg.epochs * len(ov_train),\n",
    "    'iter_warmup': 0.0,\n",
    "}\n",
    "model = create_segmenter(model_cfg)\n",
    "model.to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Segmenter(\n",
       "  (encoder): VisionTransformer(\n",
       "    (patch_embed): PatchEmbedding(\n",
       "      (proj): Conv2d(9, 192, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mlp): FeedForward(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    (head): Linear(in_features=192, out_features=1000, bias=True)\n",
       "    (pre_logits): Identity()\n",
       "  )\n",
       "  (decoder): MaskTransformer(\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mlp): FeedForward(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mlp): FeedForward(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.100)\n",
       "      )\n",
       "    )\n",
       "    (proj_dec): Linear(in_features=192, out_features=192, bias=True)\n",
       "    (decoder_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    (mask_norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "opt_args = argparse.Namespace()\n",
    "opt_vars = vars(opt_args)\n",
    "for k, v in opt_cfg.items():\n",
    "    opt_vars[k] = v\n",
    "\n",
    "optimizer = create_optimizer(opt_args, model)\n",
    "lr_scheduler = create_scheduler(opt_args, optimizer)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "if cfg.train_subdir == 'last' and tcfg.last_checkpoint_fpath.exists():\n",
    "    checkpoint = torch.load(tcfg.last_checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "    tcfg.last_epoch = checkpoint['last_epoch']\n",
    "\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6, 256, 256]) torch.Size([10, 6, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "i_batch = 0\n",
    "gt_item = ov_train.get_gt_batch(i_batch)\n",
    "x = stack_imgs_maps(gt_item.maps_crop_tn, gt_item.maps_names, gt_item.imgs_crop_tn)\n",
    "y_gt = stack_imgs_maps(gt_item.maps_crop_tn, gt_item.maps_names)\n",
    "x, y_gt = x.to(device), y_gt.to(device)\n",
    "y_pred = model.forward(x)\n",
    "print(y_pred.shape, y_gt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.1360, grad_fn=<MinBackward1>),\n",
       " tensor(2.1602, grad_fn=<MaxBackward1>),\n",
       " tensor(0.),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.dtype, y_gt.dtype\n",
    "y_pred.min(), y_pred.max(), y_gt.min(), y_gt.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8881, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss: torch.Tensor = criterion(y_pred, y_gt)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdp_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
